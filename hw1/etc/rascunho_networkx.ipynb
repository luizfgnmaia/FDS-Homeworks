{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from scrape_scholar import *\n",
    "import sqlite3 \n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import altair as alt\n",
    "import nx_altair as nxa\n",
    "alt.renderers.enable('notebook')\n",
    "\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arrumando o input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conectando ao db\n",
    "conn = sqlite3.connect('db.db')\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Criando as tables    \n",
    "cur.executescript('''\n",
    "DROP TABLE IF EXISTS author;\n",
    "DROP TABLE IF EXISTS paper;\n",
    "DROP TABLE IF EXISTS author_paper;\n",
    "\n",
    "CREATE TABLE author(\n",
    "id INTEGER PRIMARY KEY NOT NULL,\n",
    "author TEXT NOT NULL UNIQUE);\n",
    "CREATE TABLE paper(\n",
    "id INTEGER PRIMARY KEY NOT NULL,\n",
    "paper VARCHAT NOT NULL UNIQUE);\n",
    "''')\n",
    "\n",
    "conn.commit()\n",
    "conn.close()\n",
    "\n",
    "def scrape_and_store(author_name):\n",
    "\n",
    "    conn = sqlite3.connect(\"db.db\")\n",
    "    cur = conn.cursor()\n",
    "    \n",
    "    # Coletando os dados\n",
    "    data = scrape(author_name)\n",
    "\n",
    "    # Inserindo nas tables paper e author\n",
    "    for paper in range(len(data)):\n",
    "        conn.execute(\"INSERT OR IGNORE INTO paper (paper) VALUES (?)\", [data[paper].get('title')])\n",
    "        for author in data[paper].get('authors'):\n",
    "            conn.execute(\"INSERT OR IGNORE INTO author (author) VALUES (?)\", [author])\n",
    "        \n",
    "    # Inserindo na author_paper\n",
    "    # tem algum jeito mais eficiente?    \n",
    "    author_paper = pd.DataFrame(columns = [\"paper\", \"author\"])\n",
    "    \n",
    "    for paper in range(len(data)):\n",
    "        for author in data[paper].get('authors'):\n",
    "            author_paper = author_paper.append({\"paper\" : data[paper].get('title'), 'author' : author}, ignore_index = True)\n",
    "        \n",
    "    aux_paper = []\n",
    "    cur.execute(\"SELECT * FROM paper\")\n",
    "    aux_paper = cur.fetchall()\n",
    "    aux_paper = pd.DataFrame(aux_paper, columns = [\"paper_id\", \"paper\"])\n",
    "\n",
    "    aux_author = []\n",
    "    cur.execute(\"SELECT * FROM author\")\n",
    "    aux_author = cur.fetchall()\n",
    "    aux_author = pd.DataFrame(aux_author, columns = ['author_id', 'author'])\n",
    "\n",
    "    author_paper = pd.merge(pd.merge(author_paper, aux_author), aux_paper)\n",
    "    author_paper.to_sql(\"author_paper\", con = conn, if_exists = \"append\")\n",
    "\n",
    "    conn.commit()\n",
    "    conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrape_and_store(\"Rodrigo Targino\")\n",
    "conn = sqlite3.connect('db.db')\n",
    "cur = conn.cursor()\n",
    "inpt = pd.read_sql(\"SELECT * FROM author_paper\", conn)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte do NetworkX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções pros gráficos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_authors():\n",
    "    \n",
    "    conn = sqlite3.connect('db.db')\n",
    "    cur = conn.cursor()\n",
    "    inpt = pd.read_sql(\"SELECT * FROM author_paper\", conn)\n",
    "    conn.close()\n",
    "    \n",
    "    inpt = inpt[['paper', 'author']]\n",
    "    inpt['values'] = 1\n",
    "    \n",
    "    lst = list(inpt['author'])\n",
    "    names = sorted(list(set(lst)))\n",
    "\n",
    "    inpt = inpt.pivot_table(index = 'paper', columns = 'author').fillna(0)\n",
    "    inpt.index.name = None\n",
    "\n",
    "    cols = inpt.columns\n",
    "    X = sp.csr_matrix(inpt.astype(int).values)\n",
    "    Xc = X.T * X  \n",
    "    Xc.setdiag(0)  \n",
    "\n",
    "    inpt = pd.DataFrame(Xc.todense(), index = cols, columns=cols)\n",
    "    graph = nx.from_numpy_matrix(inpt.values)\n",
    "    graph = nx.relabel_nodes(graph, dict(enumerate(names)))\n",
    "    \n",
    "    cont = 0\n",
    "    for n in graph.nodes():\n",
    "        graph.nodes[n]['author'] = names[cont]\n",
    "        cont += 1\n",
    "    \n",
    "    nxa.draw_networkx(G = graph, pos = nx.spring_layout(graph), node_tooltip = ['author']).interactive()\n",
    "    limits = pylab.axis('off')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAA5FJREFUeJzt1MENwCAQwLDS/Xc+tgCJ2BPklTUzHwDv+28HAHCG4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QIThA0QYPkCE4QNEGD5AhOEDRBg+QMQGL4sE9RSocXsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "conn = sqlite3.connect('db.db')\n",
    "cur = conn.cursor()\n",
    "inpt = pd.read_sql(\"SELECT * FROM author_paper\", conn)\n",
    "conn.close()\n",
    "\n",
    "inpt = inpt[['paper', 'author']]\n",
    "inpt['values'] = 1\n",
    "\n",
    "lst = list(inpt['author'])\n",
    "names = sorted(list(set(lst)))\n",
    "\n",
    "inpt = inpt.pivot_table(index = 'paper', columns = 'author').fillna(0)\n",
    "inpt.index.name = None\n",
    "\n",
    "cols = inpt.columns\n",
    "X = sp.csr_matrix(inpt.astype(int).values)\n",
    "Xc = X.T * X  \n",
    "Xc.setdiag(0)  \n",
    "\n",
    "inpt = pd.DataFrame(Xc.todense(), index = cols, columns=cols)\n",
    "graph = nx.from_numpy_matrix(inpt.values)\n",
    "graph = nx.relabel_nodes(graph, dict(enumerate(names)))\n",
    "\n",
    "cont = 0\n",
    "for n in graph.nodes():\n",
    "    graph.nodes[n]['author'] = names[cont]\n",
    "    cont += 1\n",
    "\n",
    "pos = nx.spring_layout(graph)    \n",
    "    \n",
    "nxa.draw_networkx(G = graph, pos = pos, node_tooltip = ['author']).interactive()\n",
    "limits = pylab.axis('off')  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<networkx.classes.graph.Graph at 0x4d070c1ef0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_authors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_papers():\n",
    "    \n",
    "    conn = sqlite3.connect('db.db')\n",
    "    cur = conn.cursor()\n",
    "    inpt = pd.read_sql(\"SELECT * FROM author_paper\", conn)\n",
    "    conn.close()\n",
    "    \n",
    "    inpt = inpt[['paper', 'author']]\n",
    "    inpt['values'] = 1\n",
    "    inpt\n",
    "    \n",
    "    lst = list(inpt['paper'])\n",
    "    names = sorted(list(set(lst)))\n",
    "\n",
    "    inpt = inpt.pivot_table(index = 'author', columns = 'paper').fillna(0)\n",
    "    inpt.index.name = None\n",
    "\n",
    "    cols = inpt.columns\n",
    "    X = sp.csr_matrix(inpt.astype(int).values)\n",
    "    Xc = X.T * X  \n",
    "    Xc.setdiag(0)  \n",
    "\n",
    "    inpt = pd.DataFrame(Xc.todense(), index = cols, columns=cols)\n",
    "    graph = nx.from_numpy_matrix(inpt.values)\n",
    "    graph = nx.relabel_nodes(graph, dict(enumerate(names)))\n",
    "\n",
    "    nx.draw_networkx(graph, with_labels = True)\n",
    "    limits = pylab.axis('off')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_papers()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
